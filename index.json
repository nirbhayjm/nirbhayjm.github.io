[{"authors":["nirbhay"],"categories":null,"content":"I am a PhD student advised by Prof. Dhruv Batra in the School of Interactive Computing within the College of Computing at Georgia Tech. I graduated from IIT Kanpur in 2017 with a bachelor\u0026rsquo;s degree in Computer Science, where I worked with Prof. Piyush Rai.\nMy long term goal is to develop algorithms that are capable of intelligent and flexible decision making. I seek to build artificial agents capable of reasoning under uncertainty, learning efficiently from past decisions and plan long-term. My research covers the areas of reinforcement learning, information theory and bayesian inference.\nWhen I\u0026rsquo;m not occupied with my academic endeavors, I like to hone my speed solving timings for the Rubik\u0026rsquo;s Cube and its other variants, such as the 4 x 4, one-handed 3 x 3, Pyraminx and many more! My official World Cube Association record for fastest single solve of the 3 x 3 is 15.33 seconds.\nYou can find my resume here.\n","date":1587763873,"expirydate":-62135596800,"kind":"taxonomy","lang":"en","lastmod":1587763873,"objectID":"49d0cb3898140a0bc59e0b08b749ae05","permalink":"https://nirbhayjm.github.io/author/nirbhay-modhe/","publishdate":"0001-01-01T00:00:00Z","relpermalink":"/author/nirbhay-modhe/","section":"authors","summary":"I am a PhD student advised by Prof. Dhruv Batra in the School of Interactive Computing within the College of Computing at Georgia Tech. I graduated from IIT Kanpur in 2017 with a bachelor\u0026rsquo;s degree in Computer Science, where I worked with Prof.","tags":null,"title":"Nirbhay Modhe","type":"authors"},{"authors":["**Nirbhay Modhe**","[Prithvijit Chattopadhyay](https://prithv1.xyz/)","[Mohit Sharma](https://ms-sharma.github.io/)","[Abhishek Das](https://abhishekdas.com/)","[Devi Parikh](https://www.cc.gatech.edu/~parikh/)","[Dhruv Batra](https://www.cc.gatech.edu/~dbatra/index.html)","[Ramakrishna Vedantam](https://vrama91.github.io/)"],"categories":[],"content":"","date":1587763873,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587763873,"objectID":"b2c143798445efed1ee66100589e2873","permalink":"https://nirbhayjm.github.io/publication/ir-vic/","publishdate":"2020-04-24T17:31:13-04:00","relpermalink":"/publication/ir-vic/","section":"publication","summary":"We present a hierarchical reinforcement learning (HRL) or options framework for identifying decision states. Informally speaking, these are states considered important by the agent's policy e.g. , for navigation, decision states would be crossroads or doors where an agent needs to make strategic decisions. While previous work (most notably Goyal et. al., 2019) discovers decision states in a task/goal specific (or ‘supervised’) manner, we do so in a goal-independent (or ‘unsupervised’) manner, i.e. entirely without any goal or extrinsic rewards. Our approach combines two hitherto disparate ideas -  1) *intrinsic control* (Gregor et. al., 2016, Eysenbach et. al., 2018): learning a set of options that allow an agent to reliably reach a diverse set of states, and 2) information bottleneck (Tishby et. al., 2000): penalizing mutual information between the option $\\Omega$ and the states $s_t$ visited in the trajectory. The former encourages an agent to reliably explore the environment; the latter allows identification of decision states as the ones with high mutual information $I(\\Omega; a_t | s_t)$ despite the bottleneck. Our results demonstrate that 1) our model learns interpretable decision states in an unsupervised manner, and 2) these learned decision states transfer to goal-driven tasks in new environments, effectively guide exploration, and improve performance.","tags":["reinforcement learning"],"title":"Unsupervised Discovery of Decision States for Transfer in Reinforcement Learning","type":"publication"},{"authors":["[Vikas Jain\u0026ast;](https://github.com/vikasjiitk)","**Nirbhay Modhe**\u0026ast;","[Piyush Rai](http://www.cse.iitk.ac.in/users/piyush/)"],"categories":[],"content":"","date":1493069473,"expirydate":-62135596800,"kind":"page","lang":"en","lastmod":1587763873,"objectID":"90aa6c1a3c0ca26fd0d687e91b094cd3","permalink":"https://nirbhayjm.github.io/publication/gen-eml/","publishdate":"2017-04-24T17:31:13-04:00","relpermalink":"/publication/gen-eml/","section":"publication","summary":"We present a scalable, generative framework for multi-label learning with missing labels. Our framework consists of a latent factor model for the binary label matrix, which is coupled with an exposure model to account for label missingness (i.e., whether a zero in the label matrix is indeed a zero or denotes a missing observation). The underlying latent factor model also assumes that the low-dimensional embeddings of each label vector are directly conditioned on the respective feature vector of that example. Our generative framework admits a simple inference procedure, such that the parameter estimation reduces to a sequence of simple weighted least-square regression problems, each of which can be solved easily, efficiently, and in parallel. Moreover, inference can also be performed in an online fashion using mini-batches of training examples, which makes our framework scalable for large data sets, even when using moderate computational resources. We report both quantitative and qualitative results for our framework on several benchmark data sets, comparing it with a number of state-of-the-art methods.\"","tags":["multilabel learning"],"title":"Scalable Generative Models for Multi-label Learning with Missing Labels","type":"publication"}]